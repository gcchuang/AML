{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a function to get the coordinates of the patches in the WSIs, according to the tile_selection.tsv file\n",
    "def get_coordinates(tile_selection_path,patches_size,left_proportion,top_proportion):\n",
    "    df = pd.read_table(tile_selection_path)\n",
    "    # select the patches with Keep = 1 and in the lower right side of the WSI based on the proportion\n",
    "    df = df.loc[(df[\"Keep\"] == 1) & (df[\"Column\"]>=int(max(df[\"Column\"])*left_proportion))& (df[\"Row\"]>=int(max(df[\"Row\"])*top_proportion))]\n",
    "    # group the rows by index to form a list of tuples\n",
    "    tuples = [(x, y) for x, y in zip(df['Row']*patches_size, df['Column']*patches_size)]\n",
    "    patches_num = len(tuples)\n",
    "    return tuples , patches_num\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if all the slides are processed to patches, and find the number of patches is less than 10000\n",
    "directory_path = '/home/exon_storage1/aml_slide/patches/'\n",
    "for file in os.listdir(directory_path):\n",
    "    if  os.path.exists(directory_path+file+\"/rightside_patch\"):\n",
    "        patches_path = directory_path+file+\"/rightside_patch/\"\n",
    "        number_of_patches = len(os.listdir(patches_path))\n",
    "        if number_of_patches <= 10000:\n",
    "            print( file+\" : \"+str(len(os.listdir(patches_path))))\n",
    "    else:\n",
    "        print(file+\" is not processed yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script is used to normalize the patches and save them in a new folder, with a blurry filter\n",
    "sys.path.insert(1, '/home/weber50432/AML_image_processing/HEnorm_python/')\n",
    "from normalizeStaining import normalizeStaining , is_blurry\n",
    "directory_path = '/home/weber50432/AML_image_processing/PyHIST/output/'\n",
    "for file in os.listdir(directory_path):\n",
    "    if  os.path.exists(directory_path+file+\"/rightside_patch\"):\n",
    "        patches_path = directory_path+file+\"/rightside_patch/\"\n",
    "        if os.path.exists(directory_path+file+\"/rightside_patch_norm\"):\n",
    "            print(file + \" rightside_patch_norm is already created !\")\n",
    "            continue\n",
    "        else:\n",
    "            os.mkdir(directory_path+file+\"/rightside_patch_norm/\")\n",
    "        if os.path.exists(directory_path+file+\"/rightside_patch_blurry\"):\n",
    "            print(file + \" rightside_patch_blurry is already created !\")\n",
    "        else:\n",
    "            os.mkdir(directory_path+file+\"/rightside_patch_blurry/\")\n",
    "        patches_path_blurry = directory_path+file+\"/rightside_patch_blurry/\"\n",
    "        patches_path_norm = directory_path+file+\"/rightside_patch_norm/\"\n",
    "        for img in os.listdir(patches_path):\n",
    "            if img.endswith(\".png\"):\n",
    "                img_num = str(img)\n",
    "                img_path = patches_path+img\n",
    "                img = np.array(Image.open(img_path))\n",
    "                Inorm, H, E = normalizeStaining(img = img,\n",
    "                      saveFile = None,\n",
    "                      Io = 240,\n",
    "                      alpha = 1,\n",
    "                      beta = 0.15)\n",
    "                if is_blurry(Inorm):\n",
    "                    Image.fromarray(Inorm).save(patches_path_blurry+img_num)\n",
    "                    # os.remove(img_path)\n",
    "                    print(img_num+\" is blurry !\")\n",
    "                else:\n",
    "                    Image.fromarray(Inorm).save(patches_path_norm+img_num)\n",
    "                    print(img_num+\" is saved !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5120, 121344), (5120, 121856), (5120, 161280), (5632, 117760), (5632, 118272)]\n",
      "10982\n"
     ]
    }
   ],
   "source": [
    "patches_size = 512\n",
    "list, num = get_coordinates('/home/weber50432/AML_image_processing/PyHIST/output/A13/tile_selection.tsv',patches_size,0.5,0)\n",
    "print(list[:5])\n",
    "print(num)\n",
    "grid = []\n",
    "grid.append(list)\n",
    "output = {\n",
    "    \"slides\": [\"my/full/path/slide01.svs\", \"my/full/path/slide02.svs\"],\n",
    "    \"grid\": grid\n",
    "    ,\n",
    "    \"targets\": [0, 1],\n",
    "    \"mult\": patches_size/224,\n",
    "    \"level\": 0,\n",
    "}\n",
    "\n",
    "torch.save(output, \"./data.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles: 10982\n"
     ]
    }
   ],
   "source": [
    "lib = torch.load(\"./data.pt\")\n",
    "grid = []\n",
    "slideIDX = []\n",
    "for i,g in enumerate(lib['grid']):\n",
    "  grid.extend(g)\n",
    "  slideIDX.extend([i]*len(g))\n",
    "\n",
    "print('Number of tiles: {}'.format(len(grid)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f232f962faf98c666526a91f43bdf4fdf8ec3ccc29d01b8c9967d9c5017bdac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
