{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "import utility_functions as uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_size = 64\n",
    "target_gene = \"NPM1\"\n",
    "cell_type_list = ['Neutrophil', 'Metamyelocyte', 'Myelocyte', 'Promyelocyte', 'Blast', 'Lymphocyte', 'Monocyte', 'Eosinophil', 'Basophil']\n",
    "target_gene_split = target_gene.split(\" \")[0]\n",
    "split_size = 2000\n",
    "level = 0\n",
    "slide_path = \"/home/exon_storage1/aml_slide/\"\n",
    "info_file_path = \"/home/weber50432/AML_image_processing/code_use_csv/changeSlideName.csv\"\n",
    "output_path =f\"/home/weber50432/AML_image_processing/lib/{target_gene_split}_cell_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_list = uf.get_slides_list_number(f\"{slide_path}single_cell_image/\")\n",
    "target_list = uf.get_targets_list(target_gene,slide_list,info_file_path)\n",
    "#get the cells number of each slide\n",
    "df = pd.DataFrame({'Slide': [],\"Target\":[] ,'cell_number': []})\n",
    "for index,slide_num in enumerate(slide_list):\n",
    "    cell_num = 0\n",
    "    for target_cell in cell_type_list:\n",
    "        cell_path = f\"{slide_path}single_cell_image/A{slide_num}/{target_cell}\"\n",
    "        if os.path.exists(cell_path):\n",
    "            cell_num = len(os.listdir(cell_path)) + cell_num\n",
    "            df.loc[index] = [slide_num,target_list[index],cell_num]\n",
    "# count the positive and negative slide number\n",
    "# print(f\"positive target: {df['Target'].sum()}, negative target: {len(df)-df['Target'].sum()}\")\n",
    "df.to_csv(f\"/home/weber50432/AML_image_processing/lib/{target_gene_split}_select_cell_num.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train positive target: 70, negative target: 330\n",
      "val positive target: 11, negative target: 45\n",
      "test positive target: 20, negative target: 96\n",
      "train: 69.93%, val: 9.79%, test: 20.28%\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "df = pd.read_csv(f\"/home/weber50432/AML_image_processing/lib/{target_gene_split}_Myelocyte_num.csv\")\n",
    "# # take 10% of the data as data\n",
    "# df = df.sample(frac=0.1, random_state=111)\n",
    "df_train, df_val = train_test_split(df, test_size=0.3, random_state=111)\n",
    "df_val, df_test = train_test_split(df_val, test_size=0.67, random_state=111)\n",
    "# show the number of positive and negative target in each dataframe\n",
    "print(f\"train positive target: {df_train['Target'].sum()}, negative target: {len(df_train)-df_train['Target'].sum()}\")\n",
    "print(f\"val positive target: {df_val['Target'].sum()}, negative target: {len(df_val)-df_val['Target'].sum()}\")\n",
    "print(f\"test positive target: {df_test['Target'].sum()}, negative target: {len(df_test)-df_test['Target'].sum()}\")\n",
    "# show the proportion of total data number in each dataframe in percentage\n",
    "print(f\"train: {len(df_train)/len(df)*100:.2f}%, val: {len(df_val)/len(df)*100:.2f}%, test: {len(df_test)/len(df)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weber50432/miniconda3/envs/ML/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: positive target: 323, negative target: 330\n"
     ]
    }
   ],
   "source": [
    "# training data upsampling\n",
    "df_train_output = pd.DataFrame({'Slide': [], \"Target\": [], 'patches': []})\n",
    "for index, row in df_train.iterrows():\n",
    "    slide_num = row['Slide']\n",
    "    target = row['Target']\n",
    "    patch_list = []\n",
    "    for target_cell in cell_type_list:\n",
    "        if os.path.exists(f\"{slide_path}single_cell_image/A{slide_num}/{target_cell}\"):\n",
    "            for patches in  os.listdir(f\"{slide_path}single_cell_image/A{slide_num}/{target_cell}\"):\n",
    "                patch_list.append(f\"{target_cell}/{patches}\")\n",
    "    # if target is positive, split the patches number of the slide and add it to slide_list\n",
    "    if target == 1:\n",
    "        if split_size < len(patch_list):\n",
    "            # Shuffle the original list randomly\n",
    "            random.shuffle(patch_list)\n",
    "            # split the patches list into  sublists\n",
    "            sublists = [patch_list[i:i+split_size]\n",
    "                        for i in range(0, len(patch_list)-len(patch_list) % split_size, split_size)]\n",
    "            # store the sublists into the dataframe\n",
    "            for j, sublist in enumerate(sublists):\n",
    "                df_train_output.loc[df_train_output.shape[0]] = [\n",
    "                    f\"A{slide_num}_{j+1}\", target, sublist]\n",
    "        else:\n",
    "            df_train_output.loc[df_train_output.shape[0]] = [\n",
    "                f\"A{slide_num}\", target, patch_list]\n",
    "    else:\n",
    "        if split_size < len(patch_list):\n",
    "            sublist = random.sample(patch_list, split_size)\n",
    "        else:\n",
    "            sublist = patch_list\n",
    "        df_train_output.loc[df_train_output.shape[0]] = [f\"A{slide_num}\", target, sublist]\n",
    "print(\n",
    "    f\"training: positive target: {df_train_output['Target'].sum()}, negative target: {len(df_train_output)-df_train_output['Target'].sum()}\")\n",
    "# save the data as a .pt file\n",
    "train_output = {\n",
    "    \"slides\": df_train_output['Slide'].tolist(),\n",
    "    \"grid\": df_train_output['patches'].tolist(),\n",
    "    \"targets\": df_train_output['Target'].tolist(),\n",
    "    \"mult\": patches_size/224,\n",
    "    \"level\": level,\n",
    "}\n",
    "torch.save(train_output, \"{}/{}_train_data.pt\".format(output_path, target_gene_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: positive target: 1, negative target: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weber50432/miniconda3/envs/ML/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# validation data without upsampling\n",
    "df_temp = pd.DataFrame({'Slide': [],\"Target\":[] ,'patches': []})\n",
    "for index,row in df_val.iterrows():\n",
    "    slide_num = row['Slide']\n",
    "    target = row['Target']\n",
    "    patch_list = os.listdir(f\"{slide_path}single_cell_image/A{slide_num}/Myelocyte\")\n",
    "    if split_size < len(patch_list):\n",
    "        sublist = random.sample(patch_list,split_size)\n",
    "    else:\n",
    "        sublist = patch_list\n",
    "    df_temp.loc[df_temp.shape[0]] = [f\"A{slide_num}\",target,sublist]\n",
    "df_val = df_temp\n",
    "print(f\"validation: positive target: {df_val['Target'].sum()}, negative target: {len(df_val)-df_val['Target'].sum()}\")\n",
    "val_output = {\n",
    "        \"slides\": df_val['Slide'].tolist(),\n",
    "        \"grid\": df_val['patches'].tolist(),\n",
    "        \"targets\": df_val['Target'].tolist(),\n",
    "        \"mult\": patches_size/224,\n",
    "        \"level\": level,\n",
    "    }\n",
    "torch.save(val_output, \"{}/{}_val_data.pt\".format(output_path,target_gene_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: positive target: 1, negative target: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weber50432/miniconda3/envs/ML/lib/python3.9/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# test data without upsampling\n",
    "df_temp = pd.DataFrame({'Slide': [],\"Target\":[] ,'patches': []})\n",
    "for index,row in df_test.iterrows():\n",
    "    slide_num = row['Slide']\n",
    "    target = row['Target']\n",
    "    patch_list = os.listdir(f\"{slide_path}ROI_level0_pixel512/A{slide_num}\")\n",
    "    if split_size < len(patch_list):\n",
    "        sublist = random.sample(patch_list,split_size)\n",
    "    else:\n",
    "        sublist = patch_list\n",
    "    df_temp.loc[df_temp.shape[0]] = [f\"A{slide_num}\",target,sublist]\n",
    "df_test = df_temp\n",
    "print(f\"test: positive target: {df_test['Target'].sum()}, negative target: {len(df_test)-df_test['Target'].sum()}\")\n",
    "test_output = {\n",
    "        \"slides\": df_test['Slide'].tolist(),\n",
    "        \"grid\": df_test['patches'].tolist(),\n",
    "        \"targets\": df_test['Target'].tolist(),\n",
    "        \"mult\": patches_size/224,\n",
    "        \"level\": level,\n",
    "    }\n",
    "torch.save(test_output, \"{}/{}_test_data.pt\".format(output_path,target_gene_split))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
