{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.6, Numpy 1.16.2, OpenCV, scikit-image, tensorflow 1.3\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import vgg19_fastmal as vgg19\n",
    "import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random, shuffle\n",
    "\n",
    "def majority_voting(votes):\n",
    "    return max(votes,key=votes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the training and testing csv file\n",
    "# read the csv file as a dataframe\n",
    "data = pd.read_csv(\"../../lib/NPM1_slide_patch_num.csv\",header=None)\n",
    "# set the first row as the column name\n",
    "data.columns = data.iloc[0]\n",
    "# random select 20% of the data replace the data in the dataframe\n",
    "data = data.sample(frac=0.2,replace=True)\n",
    "data = data.reset_index(drop=True)\n",
    "# add A to the first column\n",
    "data.iloc[:,0] = 'A' + data.iloc[:,0].astype(str)\n",
    "# split the dataframe into training and testing by 80% and 20%\n",
    "df_train , df_test = train_test_split (data,test_size=0.2,random_state=100)\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slide</th>\n",
       "      <th>Target</th>\n",
       "      <th>patches_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>A957</td>\n",
       "      <td>0</td>\n",
       "      <td>2453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>A337</td>\n",
       "      <td>0</td>\n",
       "      <td>3398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>A488</td>\n",
       "      <td>0</td>\n",
       "      <td>8632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A518</td>\n",
       "      <td>1</td>\n",
       "      <td>6641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A1066</td>\n",
       "      <td>0</td>\n",
       "      <td>3433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>A811</td>\n",
       "      <td>0</td>\n",
       "      <td>1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A770</td>\n",
       "      <td>0</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A507</td>\n",
       "      <td>0</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A640</td>\n",
       "      <td>0</td>\n",
       "      <td>3712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A721</td>\n",
       "      <td>1</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>A536</td>\n",
       "      <td>0</td>\n",
       "      <td>3109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>A636</td>\n",
       "      <td>0</td>\n",
       "      <td>4316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A292</td>\n",
       "      <td>0</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>A642</td>\n",
       "      <td>0</td>\n",
       "      <td>2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>A514</td>\n",
       "      <td>0</td>\n",
       "      <td>3876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A427</td>\n",
       "      <td>0</td>\n",
       "      <td>1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>A514</td>\n",
       "      <td>0</td>\n",
       "      <td>3876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>A993</td>\n",
       "      <td>0</td>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A457</td>\n",
       "      <td>1</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A311</td>\n",
       "      <td>0</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A960</td>\n",
       "      <td>1</td>\n",
       "      <td>1687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>A768</td>\n",
       "      <td>1</td>\n",
       "      <td>1505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>A946</td>\n",
       "      <td>1</td>\n",
       "      <td>2351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0    Slide Target patches_number\n",
       "88    A957      0           2453\n",
       "80    A337      0           3398\n",
       "50    A488      0           8632\n",
       "28    A518      1           6641\n",
       "95   A1066      0           3433\n",
       "74    A811      0           1239\n",
       "26    A770      0           1945\n",
       "32    A507      0            986\n",
       "33    A640      0           3712\n",
       "25    A721      1           1067\n",
       "77    A536      0           3109\n",
       "51    A636      0           4316\n",
       "43    A292      0            992\n",
       "35    A642      0           2970\n",
       "101   A514      0           3876\n",
       "21    A427      0           1339\n",
       "110   A514      0           3876\n",
       "78    A993      0           1397\n",
       "41    A457      1           2710\n",
       "96    A311      0           1597\n",
       "29    A960      1           1687\n",
       "57    A768      1           1505\n",
       "73    A946      1           2351"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "csv_slide_ids = df_train['Slide'].tolist()\n",
    "print(len(csv_slide_ids))\n",
    "csv_labels =np.array(df_train['Target']).astype(np.uint8)\n",
    "onehot_labels = np.zeros(shape=(csv_labels.shape[0], 2), dtype=np.float32)\n",
    "onehot_labels[csv_labels==0,0]=1\n",
    "onehot_labels[csv_labels==1,1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "test_csv_slide_ids = df_test['Slide'].tolist()\n",
    "print(len(test_csv_slide_ids))\n",
    "test_csv_labels =np.array(df_test['Target']).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative train: 77\n",
      "Positive train: 15\n",
      "Negative test: 17\n",
      "Positive test: 6\n"
     ]
    }
   ],
   "source": [
    "#load the data path\n",
    "dataset = \"/home/exon_storage1/aml_slide/single_cell_image/\"\n",
    "dataset2 = None\n",
    "subdirsAll = os.listdir(dataset)\n",
    "\n",
    "selected_slides = []\n",
    "selected_labels=[]\n",
    "selected_onehot_labels = []\n",
    "\n",
    "test_slides = []\n",
    "test_labels=[]\n",
    "test_onehot_labels = []\n",
    "\n",
    "for index, slide in enumerate(csv_slide_ids):\n",
    "    if slide in subdirsAll:\n",
    "        # print(f'{slide} has label {csv_labels[index]} or {onehot_labels[index,:]}')\n",
    "        slide_path = os.path.join(dataset, slide)\n",
    "        selected_slides.append(slide_path) \n",
    "        selected_onehot_labels.append(onehot_labels[index,:])\n",
    "        selected_labels.append(csv_labels[index])\n",
    "\n",
    "for index, slide in enumerate(test_csv_slide_ids):\n",
    "    if slide in subdirsAll:\n",
    "        slide_path = os.path.join(dataset, slide)\n",
    "        # print(slide, ' has label ', test_csv_labels[index])\n",
    "        test_slides.append(slide_path) \n",
    "        test_labels.append(test_csv_labels[index])  \n",
    "\n",
    "selected_labels=np.array(selected_labels)\n",
    "positive_ids = np.nonzero(selected_labels)[0]\n",
    "negative_ids = np.nonzero(1-selected_labels)[0]\n",
    "\n",
    "# print(selected_slides[0])\n",
    "print(\"Negative train:\", np.sum(1-selected_labels))\n",
    "print(\"Positive train:\", np.sum(selected_labels))\n",
    "\n",
    "print(\"Negative test:\", np.sum(1-np.array(test_labels)))\n",
    "print(\"Positive test:\", np.sum(np.array(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/weber50432/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/weber50432/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "A957 0.0 0.0 0.4998438\n",
      "A337 0.0 0.0 0.49983564\n",
      "A488 0.0 0.0 0.49987054\n",
      "A518 1.0 0.0 0.49984232\n",
      "A1066 0.0 0.0 0.49986795\n",
      "A811 0.0 0.0 0.49986798\n",
      "A770 0.0 0.0 0.4998795\n",
      "A507 0.0 0.0 0.49984387\n",
      "A640 0.0 0.0 0.49982235\n",
      "A721 1.0 0.0 0.49985737\n",
      "A536 0.0 0.0 0.49981573\n",
      "A636 0.0 0.0 0.49986243\n",
      "A292 0.0 0.0 0.49986064\n",
      "A642 0.0 0.0 0.49987477\n",
      "A514 0.0 0.0 0.4998551\n",
      "A427 0.0 0.0 0.49984822\n",
      "A514 0.0 0.0 0.4998495\n",
      "A993 0.0 0.0 0.49984995\n",
      "A457 1.0 0.0 0.49986005\n",
      "A311 0.0 0.0 0.4998342\n",
      "A960 1.0 0.0 0.49985152\n",
      "A768 1.0 0.0 0.49984136\n",
      "A946 1.0 0.0 0.49984246\n",
      "Overall accuracy 0.7391304347826086\n",
      "Postive accuracy 0.0\n",
      "Negative accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "IMSIZE = 128\n",
    "num_labels=2\n",
    "num_steps = 0\n",
    "batch_size= 1\n",
    "rpt_interval=100\n",
    "min_nb_images = 1\n",
    "save_dir = \"../output/\"\n",
    "with tf.Session() as sess:\n",
    "    images = tf.placeholder(tf.float32, [None, IMSIZE, IMSIZE, 3])\n",
    "    true_out = tf.placeholder(tf.float32, [None, 2])\n",
    "    train_mode = tf.placeholder(tf.bool)\n",
    "\n",
    "    vgg = vgg19.Vgg19(\"../model/vgg19.npy\", imsize=IMSIZE)\n",
    "    vgg.build_avg_pool(images, train_mode=train_mode)\n",
    "    focal_loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=vgg.new_fc8, labels=true_out)) \n",
    "    train = tf.train.GradientDescentOptimizer(0.0003).minimize(focal_loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    step_pos=0\n",
    "    step_neg=0\n",
    "    for step in range(1, num_steps+1):\n",
    "        try:  \n",
    "            offset = (step * batch_size) % (len(selected_onehot_labels) - batch_size)\n",
    "            \n",
    "            if step%2==0:\n",
    "                sl_id = positive_ids[step_pos % (positive_ids.shape[0])]\n",
    "                step_pos=step_pos+1\n",
    "            else:\n",
    "                sl_id = negative_ids[step_neg % (negative_ids.shape[0])]\n",
    "                step_neg=step_neg+1\n",
    "\n",
    "            slides=utils.load_folder_random(selected_slides[sl_id], max_no_img=100, crop_size=IMSIZE)\n",
    "            if len(slides)>min_nb_images:\n",
    "                slides = np.array(slides)\n",
    "                labels = np.reshape(selected_onehot_labels[sl_id], (batch_size, num_labels))\n",
    "                _,l = sess.run([train, focal_loss], feed_dict={images: slides, true_out: labels, train_mode: True})\n",
    "            if (step % rpt_interval == 0):\n",
    "                print('Minibatch loss at step %d: %f' % (step, l))     \n",
    "            if (step % 5000 == 0):   \n",
    "                save_path = os.path.join(save_dir,dataset.split(os.path.sep)[-3]+str(step)+\"sickle_max_pool_ce_vgg19_model.npy\")\n",
    "                vgg.save_npy(sess, save_path)\n",
    "                print(\"Model saved in file: %s\" % save_path)    \n",
    "        except IOError as e:\n",
    "            print('Could not read:', selected_slides[offset], ':', e, '- it\\'s ok, skipping.')        \n",
    "# test classification again, should have a higher probability about tiger\n",
    "    prediction_csv = dataset.split(os.path.sep)[-2]+'_mv_all_normal_max_pool2.csv' \n",
    "    header=['Slide-Id', 'True', 'Predicted']\n",
    "    predictionFile= open(os.path.join(\"../output/\", prediction_csv),'w')  \n",
    "    wr = csv.writer(predictionFile, dialect='excel')\n",
    "    wr.writerow(header)    \n",
    "    predicted_classif = np.zeros(len(test_slides))\n",
    "    true_classif = np.zeros(len(test_slides))\n",
    "    for tt in range(len(test_slides)):\n",
    "        \n",
    "        classify_voting=[]\n",
    "        probs=[]\n",
    "        for run in range(1):\n",
    "        #tslides = utils.load_folder(test_slides[tt], crop_size=64)\n",
    "            tslides=utils.load_folder_random(test_slides[tt], max_no_img=4, crop_size=IMSIZE)\n",
    "        \n",
    "            tslide_id = test_slides[tt].split(os.path.sep)[-1]\n",
    "            malaria_classif=0\n",
    "            if len(tslides)>min_nb_images:\n",
    "                tslides = np.array(tslides)\n",
    "\n",
    "                prob = sess.run(vgg.new_prob, feed_dict={images: tslides, train_mode: False})\n",
    "                #print(prob)\n",
    "                classify_voting.append(np.argmax(prob))\n",
    "                probs.append(prob[0,1])\n",
    "        sel_id = list(test_csv_slide_ids).index(tslide_id)\n",
    "        true_classif[tt] = test_csv_labels[sel_id]\n",
    "        predicted_classif[tt]=majority_voting(classify_voting)\n",
    "        #predicted_classif[tt]=max(classify_voting)\n",
    "        wr.writerow([tslide_id, true_classif[tt], predicted_classif[tt], np.mean(probs)])  \n",
    "        print(tslide_id, true_classif[tt], predicted_classif[tt], np.mean(probs))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    overall_accuracy=np.mean(true_classif==predicted_classif)    \n",
    "    print('Overall accuracy', overall_accuracy)\n",
    "    true_pos = true_classif[true_classif==1]\n",
    "    pred_pos = predicted_classif[true_classif==1]\n",
    "    positive_accuracy=np.mean(true_pos==pred_pos)\n",
    "    print('Postive accuracy', positive_accuracy)\n",
    "    true_neg = true_classif[true_classif==0]    \n",
    "    pred_neg = predicted_classif[true_classif==0]\n",
    "    negative_accuracy=np.mean(true_neg==pred_neg)\n",
    "    print('Negative accuracy', negative_accuracy)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
